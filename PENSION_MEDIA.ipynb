{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3671a66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from keras.layers import Dense, LSTM, Flatten\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2be48c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla de aleatoriedad del experimento.\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "11ba9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset.\n",
    "dataframe = pd.read_csv('pension_media_2021.csv', sep=\";\", usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "values = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0d324b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PASOS=6\n",
    "\n",
    "# ajuste de la serie para formato de LSTM\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "52545456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>131.070007</td>\n",
       "      <td>152.089996</td>\n",
       "      <td>170.679993</td>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>152.089996</td>\n",
       "      <td>170.679993</td>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170.679993</td>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>299.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>299.679993</td>\n",
       "      <td>331.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>299.679993</td>\n",
       "      <td>331.630005</td>\n",
       "      <td>357.850006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-6)   var1(t-5)   var1(t-4)   var1(t-3)   var1(t-2)   var1(t-1)  \\\n",
       "6   131.070007  152.089996  170.679993  191.960007  215.429993  233.050003   \n",
       "7   152.089996  170.679993  191.960007  215.429993  233.050003  251.500000   \n",
       "8   170.679993  191.960007  215.429993  233.050003  251.500000  273.750000   \n",
       "9   191.960007  215.429993  233.050003  251.500000  273.750000  299.679993   \n",
       "10  215.429993  233.050003  251.500000  273.750000  299.679993  331.630005   \n",
       "\n",
       "       var1(t)  \n",
       "6   251.500000  \n",
       "7   273.750000  \n",
       "8   299.679993  \n",
       "9   331.630005  \n",
       "10  357.850006  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formato LSTM\n",
    "reframed = series_to_supervised(values, PASOS, 1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c99a219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 1, 6) (25,) (9, 1, 6) (9,)\n"
     ]
    }
   ],
   "source": [
    "# separación en datos de test y entrenamiento del modelo\n",
    "values = reframed.values\n",
    "n_train_days = 38 - (7+PASOS)\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "# separación en entradas y salidas\n",
    "x_train, y_train = train[:, :-1], train[:, -1]\n",
    "x_val, y_val = test[:, :-1], test[:, -1]\n",
    "# reformulación 3D vectores para LSTM\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c9a982c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n",
    "\n",
    "def crear_modeloFF():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(1, PASOS)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d7b8da3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 50)                11400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 11,451\n",
      "Trainable params: 11,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 389007.0938 - val_loss: 1167626.5000\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358989.2500 - val_loss: 1087235.8750\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338581.8438 - val_loss: 1022175.3125\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319722.8125 - val_loss: 959200.0000\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301093.8750 - val_loss: 895393.5000\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 281659.0312 - val_loss: 832525.2500\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 256058.6406 - val_loss: 711769.8750\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 207159.0625 - val_loss: 564325.8750\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 183496.8594 - val_loss: 491548.3438\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 160856.4531 - val_loss: 422877.2812\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 141993.6875 - val_loss: 359500.7812\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 123740.3203 - val_loss: 304795.7812\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 105975.5078 - val_loss: 255218.9375\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 61090.7344 - val_loss: 105665.6094\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 44609.8398 - val_loss: 68814.6172\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31934.8848 - val_loss: 39886.2031\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21724.2793 - val_loss: 19223.2090\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 13585.6465 - val_loss: 6571.8472\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7962.9932 - val_loss: 1030.6150\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4192.3164 - val_loss: 488.4703\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2164.3066 - val_loss: 2837.5061\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1139.8855 - val_loss: 6199.1587\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 794.9364 - val_loss: 9496.4482\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 728.8301 - val_loss: 12095.2451\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 756.4102 - val_loss: 13809.2236\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 805.8085 - val_loss: 14703.4131\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 840.3812 - val_loss: 14935.4736\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 830.8173 - val_loss: 14179.2998\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 794.2048 - val_loss: 12709.5039\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 747.2169 - val_loss: 11757.3750\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 729.3561 - val_loss: 10970.0781\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 723.0999 - val_loss: 10565.3926\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 721.2434 - val_loss: 10404.8789\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 720.8380 - val_loss: 10266.1006\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 721.2755 - val_loss: 10089.5684\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 720.1331 - val_loss: 9971.7949\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 722.0699 - val_loss: 9899.7461\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.9758 - val_loss: 10078.3975\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 718.0474 - val_loss: 10331.1162\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 717.7479 - val_loss: 10572.4033\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 721.0394 - val_loss: 10945.3916\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 722.9001 - val_loss: 11093.8418\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 727.7004 - val_loss: 11309.1758\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 726.7313 - val_loss: 11436.1396\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 728.7985 - val_loss: 11445.0469\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 727.4984 - val_loss: 11277.7607\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 725.6343 - val_loss: 11222.5479\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 725.6521 - val_loss: 11308.6924\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 727.6848 - val_loss: 11403.5928\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 729.2308 - val_loss: 11007.0986\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 721.7777 - val_loss: 10840.7148\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 719.9467 - val_loss: 10851.9199\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 719.9353 - val_loss: 10868.0039\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 719.7595 - val_loss: 10581.8320\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.0213 - val_loss: 10305.1162\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 716.8376 - val_loss: 10382.1992\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 720.2983 - val_loss: 10739.5020\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 718.1986 - val_loss: 10910.2295\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.8524 - val_loss: 10797.5527\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.9548 - val_loss: 10952.6992\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 720.0583 - val_loss: 11067.6934\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 720.1959 - val_loss: 10915.4414\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.0486 - val_loss: 10692.0439\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 718.5839 - val_loss: 10562.8457\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 725.9217 - val_loss: 9691.4463\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 716.5950 - val_loss: 9619.3750\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 716.7763 - val_loss: 9847.3594\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 715.6739 - val_loss: 9884.3008\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 713.8527 - val_loss: 10137.7070\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 714.9525 - val_loss: 10258.0898\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 712.5031 - val_loss: 9805.7490\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.3694 - val_loss: 8994.9688\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 725.9185 - val_loss: 8754.5557\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 728.2802 - val_loss: 9042.3740\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 720.7575 - val_loss: 9168.6914\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.3137 - val_loss: 9381.3330\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 717.5455 - val_loss: 9651.7041\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 715.5184 - val_loss: 10000.5010\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 713.3557 - val_loss: 9646.0752\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 709.3317 - val_loss: 9017.9229\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 721.7930 - val_loss: 8542.7607\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 730.7494 - val_loss: 8081.3506\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 742.5917 - val_loss: 8195.1523\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 737.1505 - val_loss: 8778.4336\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 717.7272 - val_loss: 9309.9961\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 713.6414 - val_loss: 10169.0029\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 717.3774 - val_loss: 10954.2031\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 723.1606 - val_loss: 11238.9473\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 716.9185 - val_loss: 10337.2451\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 708.4931 - val_loss: 10034.9131\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 716.0978 - val_loss: 9528.6299\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 713.0973 - val_loss: 9552.9492\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 710.2698 - val_loss: 9873.8105\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 706.1022 - val_loss: 10315.8105\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 713.1412 - val_loss: 10962.0000\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 722.0736 - val_loss: 11357.0967\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 716.3065 - val_loss: 10896.3262\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 709.3859 - val_loss: 10157.9883\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 709.4377 - val_loss: 9562.6484\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 707.7299 - val_loss: 8997.3682\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 726.0129 - val_loss: 8177.6230\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 733.6777 - val_loss: 8243.7900\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 726.8166 - val_loss: 8776.9238\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 717.2589 - val_loss: 9018.2168\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 712.8460 - val_loss: 9200.2549\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 711.5435 - val_loss: 9265.9570\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 707.4339 - val_loss: 9798.1914\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 701.4047 - val_loss: 10498.2236\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 704.7595 - val_loss: 11099.0361\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 712.6286 - val_loss: 11261.1758\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 715.6307 - val_loss: 11468.7139\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 728.4035 - val_loss: 11737.2861\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.2537 - val_loss: 11254.0918\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 714.4716 - val_loss: 10351.0215\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 704.0257 - val_loss: 10139.4307\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 704.6789 - val_loss: 9781.8994\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 703.4166 - val_loss: 10018.2490\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 700.9235 - val_loss: 10396.2725\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 709.3929 - val_loss: 10872.0918\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 706.9957 - val_loss: 10698.0830\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 709.2079 - val_loss: 10873.9648\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 708.2137 - val_loss: 10821.5244\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 703.7891 - val_loss: 10416.7588\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 706.1612 - val_loss: 10299.5205\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 710.4471 - val_loss: 9458.2031\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 704.5586 - val_loss: 9321.9014\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 702.6598 - val_loss: 9272.3057\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 703.3281 - val_loss: 9436.0264\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 704.1526 - val_loss: 9844.5352\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 699.6766 - val_loss: 9782.6367\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 702.2313 - val_loss: 10091.0664\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 698.6262 - val_loss: 10019.1934\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 699.5070 - val_loss: 10108.0674\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 696.1041 - val_loss: 10502.6953\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 705.5167 - val_loss: 11030.6875\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 705.4584 - val_loss: 10496.1836\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 705.2009 - val_loss: 9496.1807\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 699.5340 - val_loss: 9214.2607\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 699.9180 - val_loss: 8912.5156\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 702.9312 - val_loss: 9035.1328\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 702.9224 - val_loss: 9162.4297\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 700.3203 - val_loss: 9244.9678\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 698.2449 - val_loss: 9467.9355\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 698.4633 - val_loss: 9532.0762\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 696.1535 - val_loss: 9475.5977\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 699.0231 - val_loss: 9203.4531\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 696.2034 - val_loss: 9441.9570\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 696.6094 - val_loss: 9559.7295\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 702.0360 - val_loss: 10098.5781\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 694.9377 - val_loss: 9991.2236\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 695.4043 - val_loss: 9929.2773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 693.1165 - val_loss: 9829.2705\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 691.3452 - val_loss: 9414.2109\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 701.8987 - val_loss: 8615.7363\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 703.1490 - val_loss: 8499.5625\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 707.7859 - val_loss: 8638.4707\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 697.2593 - val_loss: 9472.2188\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 690.5683 - val_loss: 10377.7891\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 697.0486 - val_loss: 10885.6289\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 702.1735 - val_loss: 11236.7725\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 703.9347 - val_loss: 11162.7549\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 704.7976 - val_loss: 10896.7783\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 701.1058 - val_loss: 10305.0820\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 693.7488 - val_loss: 10223.5352\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 692.7597 - val_loss: 9201.9668\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 702.8321 - val_loss: 8558.4736\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 698.1937 - val_loss: 8971.5693\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 692.7953 - val_loss: 9482.5088\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 693.1536 - val_loss: 9991.4062\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 688.0831 - val_loss: 9829.7334\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 691.2532 - val_loss: 9235.4414\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 694.3328 - val_loss: 9167.5391\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 689.7636 - val_loss: 9833.2686\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 687.0094 - val_loss: 10312.6699\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 686.3540 - val_loss: 9727.4961\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 683.4294 - val_loss: 9242.3115\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 689.7592 - val_loss: 9176.8633\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 686.8810 - val_loss: 9390.8975\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 686.7550 - val_loss: 9195.0273\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 692.1866 - val_loss: 8849.4258\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 688.0126 - val_loss: 9474.7773\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 704.7606 - val_loss: 10430.6113\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 690.4920 - val_loss: 10032.2754\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 684.9852 - val_loss: 9437.8535\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 683.5403 - val_loss: 9194.9980\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 683.6365 - val_loss: 8965.2881\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 684.3256 - val_loss: 8652.0459\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 688.3762 - val_loss: 8202.7969\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 695.0518 - val_loss: 7628.4966\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 717.1156 - val_loss: 7686.3003\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 707.7863 - val_loss: 8725.7871\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 684.2173 - val_loss: 10078.8555\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 690.1962 - val_loss: 11311.2539\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 698.1222 - val_loss: 11835.8994\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 711.7380 - val_loss: 11830.1250\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 702.6973 - val_loss: 11057.6494\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 701.6750 - val_loss: 9638.5820\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 679.6242 - val_loss: 9039.0635\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 677.6122 - val_loss: 7788.2490\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 726.8867 - val_loss: 6662.6831\n"
     ]
    }
   ],
   "source": [
    "# Definición del número de epochs de entrenamiento del modelo.\n",
    "\n",
    "EPOCHS=200\n",
    " \n",
    "model = crear_modeloFF()\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "115f3a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparación de los resultados predichos por el modelo con los resultados reales de la serie.\n",
    "\n",
    "results=model.predict(x_val)\n",
    "plt.scatter(range(len(y_val)),y_val,c='g')\n",
    "plt.scatter(range(len(results)),results,c='r')\n",
    "plt.title('validación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "26fbf6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de nuevo del dataset.\n",
    "dataframe_2 = pd.read_csv('pension_media_2021.csv', sep=\";\", usecols=[1], engine='python')\n",
    "dataframe_2 = dataframe_2.values\n",
    "values_2 = dataframe_2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aa49d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recogida de los ultimos valores.\n",
    "\n",
    "values_2 = values_2[-40:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d4c0ee87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>131.070007</td>\n",
       "      <td>152.089996</td>\n",
       "      <td>170.679993</td>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>152.089996</td>\n",
       "      <td>170.679993</td>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170.679993</td>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>191.960007</td>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>299.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>215.429993</td>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>299.679993</td>\n",
       "      <td>331.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>233.050003</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>299.679993</td>\n",
       "      <td>331.630005</td>\n",
       "      <td>357.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>251.500000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>299.679993</td>\n",
       "      <td>331.630005</td>\n",
       "      <td>357.850006</td>\n",
       "      <td>385.149994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-6)   var1(t-5)   var1(t-4)   var1(t-3)   var1(t-2)   var1(t-1)\n",
       "6   131.070007  152.089996  170.679993  191.960007  215.429993  233.050003\n",
       "7   152.089996  170.679993  191.960007  215.429993  233.050003  251.500000\n",
       "8   170.679993  191.960007  215.429993  233.050003  251.500000  273.750000\n",
       "9   191.960007  215.429993  233.050003  251.500000  273.750000  299.679993\n",
       "10  215.429993  233.050003  251.500000  273.750000  299.679993  331.630005\n",
       "11  233.050003  251.500000  273.750000  299.679993  331.630005  357.850006\n",
       "12  251.500000  273.750000  299.679993  331.630005  357.850006  385.149994"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PASOS = 6\n",
    "\n",
    "\n",
    "reframed_2 = series_to_supervised(values_2, PASOS, 1)\n",
    "reframed_2.drop(reframed_2.columns[[6]], axis=1, inplace=True) # Quita las columnas que queremos predecir (t).\n",
    "reframed_2.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3aab71ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1021.19, 1042.65, 1063.5 , 1090.7 , 1137.81, 1161.8 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = reframed_2.values\n",
    "x_test = values[33:, :] #Coge la ultima columna que es equivalente a la ultima fila\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b16aa58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1021.19 1042.65 1063.5  1090.7  1137.81 1161.8 ]]]\n",
      "[[[1042.65   1063.5    1090.7    1137.81   1161.8    1280.5414]]]\n",
      "[[[1063.5    1090.7    1137.81   1161.8    1280.5414 1325.575 ]]]\n",
      "[[[1090.7    1137.81   1161.8    1280.5414 1325.575  1379.6476]]]\n",
      "[[[1137.81   1161.8    1280.5414 1325.575  1379.6476 1445.2354]]]\n",
      "[[[1161.8    1280.5414 1325.575  1379.6476 1445.2354 1512.5183]]]\n",
      "[[[1280.5414 1325.575  1379.6476 1445.2354 1512.5183 1587.0785]]]\n",
      "[[[1325.575  1379.6476 1445.2354 1512.5183 1587.0785 1670.3331]]]\n",
      "[[[1379.6476 1445.2354 1512.5183 1587.0785 1670.3331 1745.5782]]]\n",
      "[[[1445.2354 1512.5183 1587.0785 1670.3331 1745.5782 1828.1288]]]\n",
      "[[[1512.5183 1587.0785 1670.3331 1745.5782 1828.1288 1916.267 ]]]\n",
      "[[[1587.0785 1670.3331 1745.5782 1828.1288 1916.267  2008.1556]]]\n",
      "[[[1670.3331 1745.5782 1828.1288 1916.267  2008.1556 2105.34  ]]]\n",
      "[[[1745.5782 1828.1288 1916.267  2008.1556 2105.34   2206.6614]]]\n",
      "[[[1828.1288 1916.267  2008.1556 2105.34   2206.6614 2311.51  ]]]\n",
      "[[[1916.267  2008.1556 2105.34   2206.6614 2311.51   2422.377 ]]]\n",
      "[[[2008.1556 2105.34   2206.6614 2311.51   2422.377  2538.6836]]]\n",
      "[[[2105.34   2206.6614 2311.51   2422.377  2538.6836 2660.45  ]]]\n",
      "[[[2206.6614 2311.51   2422.377  2538.6836 2660.45   2788.1243]]]\n",
      "[[[2311.51   2422.377  2538.6836 2660.45   2788.1243 2921.7185]]]\n",
      "[[[2422.377  2538.6836 2660.45   2788.1243 2921.7185 3061.6514]]]\n",
      "[[[2538.6836 2660.45   2788.1243 2921.7185 3061.6514 3208.4717]]]\n",
      "[[[2660.45   2788.1243 2921.7185 3061.6514 3208.4717 3362.3025]]]\n",
      "[[[2788.1243 2921.7185 3061.6514 3208.4717 3362.3025 3523.4775]]]\n",
      "[[[2921.7185 3061.6514 3208.4717 3362.3025 3523.4775 3692.371 ]]]\n",
      "[[[3061.6514 3208.4717 3362.3025 3523.4775 3692.371  3869.3262]]]\n",
      "[[[3208.4717 3362.3025 3523.4775 3692.371  3869.3262 4054.7715]]]\n",
      "[[[3362.3025 3523.4775 3692.371  3869.3262 4054.7715 4249.124 ]]]\n",
      "[[[3523.4775 3692.371  3869.3262 4054.7715 4249.124  4452.774 ]]]\n",
      "[[[3692.371  3869.3262 4054.7715 4249.124  4452.774  4666.1753]]]\n",
      "[[[3869.3262 4054.7715 4249.124  4452.774  4666.1753 4889.7974]]]\n",
      "[[[4054.7715 4249.124  4452.774  4666.1753 4889.7974 5124.13  ]]]\n",
      "[[[4249.124  4452.774  4666.1753 4889.7974 5124.13   5369.691 ]]]\n",
      "[[[4452.774  4666.1753 4889.7974 5124.13   5369.691  5627.016 ]]]\n",
      "[[[4666.1753 4889.7974 5124.13   5369.691  5627.016  5896.665 ]]]\n",
      "[[[4889.7974 5124.13   5369.691  5627.016  5896.665  6179.229 ]]]\n",
      "[[[5124.13  5369.691 5627.016 5896.665 6179.229 6475.329]]]\n",
      "[[[5369.691  5627.016  5896.665  6179.229  6475.329  6785.6123]]]\n",
      "[[[5627.016  5896.665  6179.229  6475.329  6785.6123 7110.7583]]]\n"
     ]
    }
   ],
   "source": [
    "def agregarNuevoValor(x_test,nuevoValor):\n",
    "    for i in range(x_test.shape[2]-1):\n",
    "        x_test[0][0][i] = x_test[0][0][i+1]\n",
    "    x_test[0][0][x_test.shape[2]-1]=nuevoValor\n",
    "    return x_test\n",
    " \n",
    "results=[]\n",
    "for i in range(39):\n",
    "    parcial=model.predict(x_test)\n",
    "    results.append(parcial[0])\n",
    "    print(x_test)\n",
    "    x_test=agregarNuevoValor(x_test,parcial[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4f33ae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1280.541382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1325.574951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1379.647583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1445.235352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1512.518311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1587.078491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1670.333130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1745.578247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1828.128784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1916.266968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2008.155640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2105.340088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2206.661377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2311.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2422.376953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2538.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2660.449951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2788.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2921.718506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3061.651367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3208.471680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3362.302490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3523.477539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3692.371094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3869.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4054.771484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4249.124023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4452.773926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4666.175293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4889.797363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5124.129883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5369.690918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5627.016113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5896.665039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6179.229004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6475.329102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6785.612305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>7110.758301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7451.479980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          total\n",
       "40  1280.541382\n",
       "41  1325.574951\n",
       "42  1379.647583\n",
       "43  1445.235352\n",
       "44  1512.518311\n",
       "45  1587.078491\n",
       "46  1670.333130\n",
       "47  1745.578247\n",
       "48  1828.128784\n",
       "49  1916.266968\n",
       "50  2008.155640\n",
       "51  2105.340088\n",
       "52  2206.661377\n",
       "53  2311.510010\n",
       "54  2422.376953\n",
       "55  2538.683594\n",
       "56  2660.449951\n",
       "57  2788.124268\n",
       "58  2921.718506\n",
       "59  3061.651367\n",
       "60  3208.471680\n",
       "61  3362.302490\n",
       "62  3523.477539\n",
       "63  3692.371094\n",
       "64  3869.326172\n",
       "65  4054.771484\n",
       "66  4249.124023\n",
       "67  4452.773926\n",
       "68  4666.175293\n",
       "69  4889.797363\n",
       "70  5124.129883\n",
       "71  5369.690918\n",
       "72  5627.016113\n",
       "73  5896.665039\n",
       "74  6179.229004\n",
       "75  6475.329102\n",
       "76  6785.612305\n",
       "77  7110.758301\n",
       "78  7451.479980"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.Index(range(40, 79, 1))\n",
    "\n",
    "\n",
    "prediccion1 = pd.DataFrame(results, index)\n",
    "prediccion1.columns = ['total']\n",
    "prediccion1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "34fb0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_3 = pd.read_csv('pension_media_2021.csv', sep=\";\", usecols=[1], engine='python')\n",
    "dataframe_3 = dataframe_3.values\n",
    "values_3 = dataframe_3.astype('float32')\n",
    "antiguo = pd.DataFrame(values_3)\n",
    "antiguo.columns = ['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "989d268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [antiguo, prediccion1]\n",
    "\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0cadf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "\n",
    "result.to_csv('pruebaPensionMedia.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ec5716e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se representa conjuntamente los datos obtenidos tras la predicción junto con los datos reales de la serie.\n",
    "\n",
    "\n",
    "plt.plot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89071f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c59a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251df18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a8aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
