{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1011c078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from keras.layers import Dense, LSTM, Flatten\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d1119e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla de aleatoriedad del experimento.\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c55ddd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset.\n",
    "dataframe = pd.read_csv('poblacion_16_65.csv', sep=\";\", usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "values = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f62f0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PASOS=6\n",
    "\n",
    "# ajuste de la serie para formato de LSTM\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ae30f279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21017614.0</td>\n",
       "      <td>21108668.0</td>\n",
       "      <td>21202298.0</td>\n",
       "      <td>21300704.0</td>\n",
       "      <td>21403962.0</td>\n",
       "      <td>21513652.0</td>\n",
       "      <td>21629402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21108668.0</td>\n",
       "      <td>21202298.0</td>\n",
       "      <td>21300704.0</td>\n",
       "      <td>21403962.0</td>\n",
       "      <td>21513652.0</td>\n",
       "      <td>21629402.0</td>\n",
       "      <td>21743452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21202298.0</td>\n",
       "      <td>21300704.0</td>\n",
       "      <td>21403962.0</td>\n",
       "      <td>21513652.0</td>\n",
       "      <td>21629402.0</td>\n",
       "      <td>21743452.0</td>\n",
       "      <td>21858044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21300704.0</td>\n",
       "      <td>21403962.0</td>\n",
       "      <td>21513652.0</td>\n",
       "      <td>21629402.0</td>\n",
       "      <td>21743452.0</td>\n",
       "      <td>21858044.0</td>\n",
       "      <td>21973084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21403962.0</td>\n",
       "      <td>21513652.0</td>\n",
       "      <td>21629402.0</td>\n",
       "      <td>21743452.0</td>\n",
       "      <td>21858044.0</td>\n",
       "      <td>21973084.0</td>\n",
       "      <td>22089562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-6)   var1(t-5)   var1(t-4)   var1(t-3)   var1(t-2)   var1(t-1)  \\\n",
       "6   21017614.0  21108668.0  21202298.0  21300704.0  21403962.0  21513652.0   \n",
       "7   21108668.0  21202298.0  21300704.0  21403962.0  21513652.0  21629402.0   \n",
       "8   21202298.0  21300704.0  21403962.0  21513652.0  21629402.0  21743452.0   \n",
       "9   21300704.0  21403962.0  21513652.0  21629402.0  21743452.0  21858044.0   \n",
       "10  21403962.0  21513652.0  21629402.0  21743452.0  21858044.0  21973084.0   \n",
       "\n",
       "       var1(t)  \n",
       "6   21629402.0  \n",
       "7   21743452.0  \n",
       "8   21858044.0  \n",
       "9   21973084.0  \n",
       "10  22089562.0  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formato LSTM\n",
    "reframed = series_to_supervised(values, PASOS, 1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0cef9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 1, 6) (90,) (7, 1, 6) (7,)\n"
     ]
    }
   ],
   "source": [
    "# separación en datos de test y entrenamiento del modelo\n",
    "values = reframed.values\n",
    "n_train_days = 103 - (7+PASOS)\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "# separación en entradas y salidas\n",
    "x_train, y_train = train[:, :-1], train[:, -1]\n",
    "x_val, y_val = test[:, :-1], test[:, -1]\n",
    "# reformulación 3D vectores para LSTM\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c0ebf917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n",
    "\n",
    "def crear_modeloFF():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(1, PASOS)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8c9ea553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 50)                11400     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 11,451\n",
      "Trainable params: 11,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 825566399823872.0000 - val_loss: 944069446467584.0000\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 643573670215680.0000 - val_loss: 722696363048960.0000\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 483265525841920.0000 - val_loss: 526790355320832.0000\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 344336789143552.0000 - val_loss: 365791425855488.0000\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 240733655138304.0000 - val_loss: 251853291913216.0000\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 160207581741056.0000 - val_loss: 157067859984384.0000\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 94938188480512.0000 - val_loss: 85193033515008.0000\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 48594614747136.0000 - val_loss: 38446269726720.0000\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 20581017714688.0000 - val_loss: 13727688556544.0000\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6981701074944.0000 - val_loss: 3561691283456.0000\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1829652660224.0000 - val_loss: 568643747840.0000\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 406572564480.0000 - val_loss: 31219449856.0000\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 154145013760.0000 - val_loss: 19263365120.0000\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131263438848.0000 - val_loss: 39812403200.0000\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132930519040.0000 - val_loss: 42797441024.0000\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133152063488.0000 - val_loss: 40359489536.0000\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132252745728.0000 - val_loss: 34872094720.0000\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134849970176.0000 - val_loss: 25270736896.0000\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132292329472.0000 - val_loss: 27685654528.0000\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132477558784.0000 - val_loss: 32698286080.0000\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132347985920.0000 - val_loss: 33944367104.0000\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132376231936.0000 - val_loss: 29991276544.0000\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134324854784.0000 - val_loss: 26394120192.0000\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132324515840.0000 - val_loss: 29262577664.0000\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133324759040.0000 - val_loss: 37440409600.0000\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132885233664.0000 - val_loss: 29261271040.0000\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133257420800.0000 - val_loss: 35096047616.0000\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132601217024.0000 - val_loss: 28686057472.0000\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132224491520.0000 - val_loss: 27646693376.0000\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132109508608.0000 - val_loss: 30099318784.0000\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132710653952.0000 - val_loss: 32810045440.0000\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132253450240.0000 - val_loss: 29596123136.0000\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133735292928.0000 - val_loss: 25785485312.0000\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132504772608.0000 - val_loss: 32563818496.0000\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132630487040.0000 - val_loss: 29670291456.0000\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132253368320.0000 - val_loss: 29726660608.0000\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132208443392.0000 - val_loss: 30184599552.0000\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132852293632.0000 - val_loss: 30684452864.0000\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132436721664.0000 - val_loss: 32968001536.0000\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133491073024.0000 - val_loss: 34480533504.0000\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132131274752.0000 - val_loss: 30967048192.0000\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132599562240.0000 - val_loss: 28907972608.0000\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132638629888.0000 - val_loss: 25335599104.0000\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132499644416.0000 - val_loss: 29869264896.0000\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132433969152.0000 - val_loss: 27431522304.0000\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132909924352.0000 - val_loss: 34970234880.0000\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133677932544.0000 - val_loss: 28724242432.0000\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133434474496.0000 - val_loss: 31088826368.0000\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132180860928.0000 - val_loss: 32554381312.0000\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132040286208.0000 - val_loss: 31802781696.0000\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133606432768.0000 - val_loss: 27071195136.0000\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134335889408.0000 - val_loss: 38759014400.0000\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133675081728.0000 - val_loss: 27764115456.0000\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132497465344.0000 - val_loss: 31804362752.0000\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132249026560.0000 - val_loss: 33787009024.0000\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132618403840.0000 - val_loss: 34302183424.0000\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135633600512.0000 - val_loss: 21941278720.0000\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132225990656.0000 - val_loss: 34064658432.0000\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133334409216.0000 - val_loss: 36421013504.0000\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132538630144.0000 - val_loss: 26036793344.0000\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133242404864.0000 - val_loss: 29247361024.0000\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132265582592.0000 - val_loss: 33037266944.0000\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 134139723776.0000 - val_loss: 34756632576.0000\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133361975296.0000 - val_loss: 30540609536.0000\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132788543488.0000 - val_loss: 25872820224.0000\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134415081472.0000 - val_loss: 41480491008.0000\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132113514496.0000 - val_loss: 28636059648.0000\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132053000192.0000 - val_loss: 29386932224.0000\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132980989952.0000 - val_loss: 26234603520.0000\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131933659136.0000 - val_loss: 32458762240.0000\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132986445824.0000 - val_loss: 35194580992.0000\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132884488192.0000 - val_loss: 26594115584.0000\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132666957824.0000 - val_loss: 35410243584.0000\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132697866240.0000 - val_loss: 28245094400.0000\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132588208128.0000 - val_loss: 32899952640.0000\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133281824768.0000 - val_loss: 26489612288.0000\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134068944896.0000 - val_loss: 30176686080.0000\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134524493824.0000 - val_loss: 41204056064.0000\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135124213760.0000 - val_loss: 22119868416.0000\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132679548928.0000 - val_loss: 30722420736.0000\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 137391267840.0000 - val_loss: 41647624192.0000\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131260956672.0000 - val_loss: 21537404928.0000\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133151653888.0000 - val_loss: 22774626304.0000\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 131792568320.0000 - val_loss: 33190193152.0000\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133076934656.0000 - val_loss: 33168625664.0000\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132237492224.0000 - val_loss: 35617214464.0000\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135152975872.0000 - val_loss: 24649957376.0000\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133872500736.0000 - val_loss: 39296864256.0000\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132209319936.0000 - val_loss: 28080691200.0000\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 136784199680.0000 - val_loss: 20415997952.0000\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131309502464.0000 - val_loss: 43858386944.0000\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133582757888.0000 - val_loss: 31004446720.0000\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132587405312.0000 - val_loss: 27571421184.0000\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133146230784.0000 - val_loss: 32943374336.0000\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133902901248.0000 - val_loss: 25937117184.0000\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131700326400.0000 - val_loss: 31869851648.0000\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133515493376.0000 - val_loss: 35677175808.0000\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134396542976.0000 - val_loss: 24945055744.0000\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132943126528.0000 - val_loss: 28781922304.0000\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133016453120.0000 - val_loss: 31005952000.0000\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134198329344.0000 - val_loss: 30463266816.0000\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132131495936.0000 - val_loss: 25631385600.0000\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134638354432.0000 - val_loss: 27583002624.0000\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132143529984.0000 - val_loss: 25537333248.0000\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132805181440.0000 - val_loss: 31280746496.0000\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132292894720.0000 - val_loss: 28502085632.0000\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135229833216.0000 - val_loss: 39849066496.0000\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135090364416.0000 - val_loss: 18793148416.0000\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135176847360.0000 - val_loss: 36778897408.0000\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131700187136.0000 - val_loss: 30000402432.0000\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131956940800.0000 - val_loss: 26396934144.0000\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132002807808.0000 - val_loss: 36615061504.0000\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132446937088.0000 - val_loss: 23654348800.0000\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132267450368.0000 - val_loss: 29385500672.0000\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133957689344.0000 - val_loss: 29220974592.0000\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132443979776.0000 - val_loss: 46982516736.0000\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134943391744.0000 - val_loss: 21742284800.0000\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 136459206656.0000 - val_loss: 37246930944.0000\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131672907776.0000 - val_loss: 32967538688.0000\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132409786368.0000 - val_loss: 30372448256.0000\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134192553984.0000 - val_loss: 28575336448.0000\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132737368064.0000 - val_loss: 36933525504.0000\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132434714624.0000 - val_loss: 32147978240.0000\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133418909696.0000 - val_loss: 27433336832.0000\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131568975872.0000 - val_loss: 26725562368.0000\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132215283712.0000 - val_loss: 28252901376.0000\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132344668160.0000 - val_loss: 31132014592.0000\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132324958208.0000 - val_loss: 27841396736.0000\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132285054976.0000 - val_loss: 25568210944.0000\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 131730595840.0000 - val_loss: 27905366016.0000\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131718004736.0000 - val_loss: 29837496320.0000\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 136158257152.0000 - val_loss: 32529852416.0000\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132320641024.0000 - val_loss: 24301381632.0000\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133990359040.0000 - val_loss: 40008577024.0000\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131787849728.0000 - val_loss: 29897060352.0000\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131687743488.0000 - val_loss: 25528547328.0000\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 139277811712.0000 - val_loss: 21887578112.0000\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 136910413824.0000 - val_loss: 51058286592.0000\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135191494656.0000 - val_loss: 27268941824.0000\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135157448704.0000 - val_loss: 24512180224.0000\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134459531264.0000 - val_loss: 50000257024.0000\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132296212480.0000 - val_loss: 24989734912.0000\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134022160384.0000 - val_loss: 21503102976.0000\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 143431647232.0000 - val_loss: 35094994944.0000\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131192610816.0000 - val_loss: 19537958912.0000\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134435504128.0000 - val_loss: 35374260224.0000\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131542884352.0000 - val_loss: 22208278528.0000\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134969163776.0000 - val_loss: 31863126016.0000\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131447087104.0000 - val_loss: 35649646592.0000\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131749519360.0000 - val_loss: 28155172864.0000\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131693174784.0000 - val_loss: 28773955584.0000\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131750133760.0000 - val_loss: 33155133440.0000\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 130720063488.0000 - val_loss: 23597344768.0000\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132985520128.0000 - val_loss: 41102897152.0000\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131762315264.0000 - val_loss: 28475682816.0000\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131166838784.0000 - val_loss: 23180957696.0000\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 130886451200.0000 - val_loss: 31183892480.0000\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 139016028160.0000 - val_loss: 20500090880.0000\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131598057472.0000 - val_loss: 33636669440.0000\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131653083136.0000 - val_loss: 37731590144.0000\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134461612032.0000 - val_loss: 20657448960.0000\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 137040519168.0000 - val_loss: 42307715072.0000\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131164946432.0000 - val_loss: 17001817088.0000\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132899389440.0000 - val_loss: 43079598080.0000\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 136919416832.0000 - val_loss: 15167974400.0000\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135415283712.0000 - val_loss: 35408949248.0000\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133943468032.0000 - val_loss: 29135194112.0000\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133265063936.0000 - val_loss: 33646553088.0000\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 136762834944.0000 - val_loss: 25703958528.0000\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133675614208.0000 - val_loss: 29488003072.0000\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134046556160.0000 - val_loss: 21171175424.0000\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 143664349184.0000 - val_loss: 38195351552.0000\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 129684979712.0000 - val_loss: 14062852096.0000\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132322500608.0000 - val_loss: 38752063488.0000\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135346266112.0000 - val_loss: 31776225280.0000\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131296100352.0000 - val_loss: 41566466048.0000\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133899476992.0000 - val_loss: 29530802176.0000\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131623763968.0000 - val_loss: 26525536256.0000\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 140818612224.0000 - val_loss: 38774546432.0000\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133259829248.0000 - val_loss: 52401561600.0000\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131336298496.0000 - val_loss: 16381371392.0000\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132079869952.0000 - val_loss: 42752745472.0000\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 134964166656.0000 - val_loss: 24995196928.0000\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132549664768.0000 - val_loss: 42615623680.0000\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 130110988288.0000 - val_loss: 19484065792.0000\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132622123008.0000 - val_loss: 47194353664.0000\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 138767925248.0000 - val_loss: 16696482816.0000\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132032634880.0000 - val_loss: 59479257088.0000\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132889051136.0000 - val_loss: 23080796160.0000\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 133231206400.0000 - val_loss: 37525151744.0000\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131203760128.0000 - val_loss: 16124908544.0000\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 135048282112.0000 - val_loss: 29755637760.0000\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 138736746496.0000 - val_loss: 38585233408.0000\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 140208783360.0000 - val_loss: 44900352000.0000\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 130096873472.0000 - val_loss: 26035238912.0000\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132546592768.0000 - val_loss: 22132312064.0000\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 131261759488.0000 - val_loss: 29915713536.0000\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 132825104384.0000 - val_loss: 32441010176.0000\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 129988149248.0000 - val_loss: 18794039296.0000\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 131995664384.0000 - val_loss: 41449140224.0000\n"
     ]
    }
   ],
   "source": [
    "# Definición del número de epochs de entrenamiento del modelo.\n",
    "\n",
    "EPOCHS=200\n",
    " \n",
    "model = crear_modeloFF()\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "17f4a184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEkCAYAAABKTLRCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAacklEQVR4nO3df4xl513f8fdnN5vYk2AbxQPeZrMz/IjiujZem6kbGhGltqEbSMBUKko6QBVRppaS2G5rocCgpos6f7RKwaUCVtM4wSg3SZ2ESLFrApbBQFr/mg2217+AELzrlWPtBmM7y6ibjffbP+7ZZHY847njmTt3zp33S7q69zz3nOd8T+LVZ845z31OqgpJktpq26ALkCRpLQwySVKrGWSSpFYzyCRJrWaQSZJazSCTJLWaQSb1UZK3JzmyYPnRJG/vZd017HPJfST5rST71tq/tNm8atAFSFtJVf2jQewjyRTw/6rqQ/3ev7TRDDJpC6iq2UHXIPWLlxalHiT5YJLPLGr770l+I8l7kzye5OtJvpLk375MP08mubr5fHaS30nyd0keA/7xEvv866bfx5L81KLvf2HBfh9LcvkS+3hNkpuSPN28bkrymua7tyc5kuQ/JDma5KtJ3rsu/4NJG8ggk3rzSeDHkpwDkGQ78NPAJ4CjwDuBc4D3Ar9+OlRW8CHg+5rXPwf+9aLv/xr4YeBcYB/w8SQ7m/3/S+A/AT/X7PcngL9dYh/TwFuAPcClwBXAryz4/oKm/zcAPw/8ZpLv7KF2adPYtEGW5KPNX4mP9LDuryd5sHn9ZZLnNqBEbSFVdQj4EnBN03QlMF9V91bV/66qv66uPwH+kG4AreSngZmqeraqngJ+Y9E+P11VT1fVqar6X8Bf0Q0igH8D/NeqeqDZ75ebGhebBH61qo5W1TG6gfizC74/2Xx/sqruAI4Db+6hdmnT2LRBBvwOsLeXFavq31XVnqraA/wP4Pf6WJe2rk8A72k+/6tmmSTvSHJvkmebP6J+DDi/h/7+AfDUguUzgijJzzV/nD3X9Hvxgn7fSPeMrZd9LOz3UNN22t9W1TcXLM8Dr+uhX2nT2LRBVlV/Cjy7sC3J9yX5QpIDSf4syYVLbPoeupeBpPX2aeDtSXYBPwV8ornf9Fngw8B3V9V5wB1Aeujvq3QD6bTdpz8kGQP+J/B+4PVNv48s6PcpupckV/I0MLZoH0/3sJ3UGps2yJYxC3ygqn4QuBH4rYVfNv/4vwf4owHUpiHXXJq7G/gY8DdV9TjwauA1wDHgm0neAfxoj13eCvxSku9swvEDC757LVBNvzSDMC5e8P1HgBuT/GC6vr/573+xTwK/kmQ0yfnAfwQ+3mN9Uiu0Zvh9ktcB/xT4dPKtP3Zfs2i1dwOfqaoXN7I2bSmfAH4X+EWAqvp6kuvohtJrgNuAz/fY1z5gP/A3dM+SPgZc3/T7WJL/BtwDnGr2+X9Ob1hVn07y+qaeNwBP0r33tfg+2X+mOxjk4Wb5002bNDSymR+smWQcuL2qLm5Gi/1FVe18mfX/HHhfVf3fjapRkjRYrbm0WFUvAH/TDDumuZxy6envk7wZ+E66f8FKkraITRtkST5JN5Te3Pxo8+fpDiX++SQPAY8CP7lgk/cAn6rNfIopSVp3m/rSoiRJK9m0Z2SSJPXCIJMktdqmHH5//vnn1/j4+KDLkCRtEgcOHPhaVY0u9d2mDLLx8XHm5uYGXYYkaZNIstRcooCXFiVJLWeQSZJazSCTJLWaQSZJajWDTJLUagaZJKnVDDJJ0vrrdGB8HLZt6753On3b1ab8HZkkqcU6HZiagvn57vKhQ91lgMnJdd+dZ2SSpPU1Pf3tEDttfr7b3gcGmSRpfR0+vLr2NVoxyJKcleT+JA8leTTJviXWuTDJPUlOJLlx0XfnJflMkieSPJ7kh9bzACRJm8zu3atrX6NezshOAFdW1aXAHmBvkrcsWudZ4Drgw0ts/9+BL1TVhcClwOOvvFxJ0qY3MwMjI2e2jYx02/tgxSCrruPN4o7mVYvWOVpVDwAnF7YnOQd4G3Bzs943quq5dahbkrRZTU7C7CyMjUHSfZ+d7ctAD+hx1GKS7cAB4PuB36yq+3rs/3uBY8DHklza9HF9Vf39KylWktQSk5N9C67FehrsUVUvVtUeYBdwRZKLe+z/VcDlwG9X1WXA3wMfXGrFJFNJ5pLMHTt2rMfuJUlb3apGLTaXBe8G9va4yRHgyIIzuM/QDbal+p6tqomqmhgdXfLZaZIkvUQvoxZHk5zXfD4buBp4opfOq+oZ4Kkkb26argIee2WlSpL0Ur3cI9sJ3NLcJ9sG3FpVtye5FqCq9ie5AJgDzgFOJbkBuKiqXgA+AHSSvBr4CvDePhyHJGmLWjHIquph4LIl2vcv+PwM3ftnS23/IDDxykuUJGl5zuwhSWo1g0yS1GoGmSSp1QwySVKrGWSSpFYzyCRJrWaQSZJazSCTJLWaQSZJajWDTJLUagaZJKnVDDJJUqsZZJK0UTodGB+Hbdu6753OoCsaCr08xkWStFadDkxNwfx8d/nQoe4ywOTk4OoaAp6RSdJGmJ7+doidNj/fbdeaGGSStBEOH15du3pmkEnSRti9e3Xt6plBJkkbYWYGRkbObBsZ6bZrTQwySdoIk5MwOwtjY5B032dnHeixDhy1KEkbZXLS4OoDz8gkSa1mkEmSWs0gkyS1mkEmSWq1FYMsyVlJ7k/yUJJHk+xbYp0Lk9yT5ESSGxd992SSg0keTDK3nsVLktTLqMUTwJVVdTzJDuCLSX6/qu5dsM6zwHXANcv08c+q6mtrK1WSpJda8Yysuo43izuaVy1a52hVPQCcXP8SJUlaXk/3yJJsT/IgcBS4s6ruW8U+CvjDJAeSTL2CGiVJWlZPQVZVL1bVHmAXcEWSi1exj7dW1eXAO4D3JXnbUislmUoyl2Tu2LFjq+hekrSVrWrUYlU9B9wN7F3FNk8370eBzwFXLLPebFVNVNXE6OjoasqSJG1hvYxaHE1yXvP5bOBq4IleOk/y2iTfcfoz8KPAI6+4WkmSFull1OJO4JYk2+kG361VdXuSawGqan+SC4A54BzgVJIbgIuA84HPJTm9r09U1RfW/zAkSVvVikFWVQ8Dly3Rvn/B52fo3j9b7AXg0rUUKEnSy3FmD0lSqxlkkqRWM8gkSa1mkEmSWs0gkyS1mkEmSWo1g0yS1GoGmSSp1QwySVKrGWSSBqvTgfFx2Lat+97pDLoitUwvcy1KUn90OjA1BfPz3eVDh7rLAJOTg6tLreIZmaTBmZ7+doidNj/fbZd6ZJBJGpzDh1fXLi3BIJM0OLt3r65dWoJBJmlwZmZgZOTMtpGRbrvUI4NM0uBMTsLsLIyNQdJ9n511oIdWxVGLkgZrctLg0pp4RiZJajWDTJLUagaZJKnVDDJJUqsZZJKkVjPIJEmttmKQJTkryf1JHkryaJJ9S6xzYZJ7kpxIcuMS329P8udJbl+vwiVJgt5+R3YCuLKqjifZAXwxye9X1b0L1nkWuA64Zpk+rgceB85ZS7GSJC224hlZdR1vFnc0r1q0ztGqegA4uXj7JLuAHwc+svZyJUk6U0/3yJpLgw8CR4E7q+q+VezjJuAXgVOrrk6SpBX0FGRV9WJV7QF2AVckubiX7ZK8EzhaVQd6WHcqyVySuWPHjvXSvSRJqxu1WFXPAXcDe3vc5K3ATyR5EvgUcGWSjy/T92xVTVTVxOjo6GrKkiRtYb2MWhxNcl7z+WzgauCJXjqvql+qql1VNQ68G/ijqvqZV16uJEln6mXU4k7gliTb6QbfrVV1e5JrAapqf5ILgDm6oxJPJbkBuKiqXuhT3ZIkAT0EWVU9DFy2RPv+BZ+foXv/7OX6uZvuZUlJktaNM3tIklrNIJMktZpBJklqNYNMktRqBpkkqdUMMklSqxlkkqRWM8gkSa1mkEmSWs0gkyS1mkEmbUadDoyPw7Zt3fdOZ9AVSZtWL5MGS9pInQ5MTcH8fHf50KHuMsDk5ODqkjYpz8ikzWZ6+tshdtr8fLdd0ksYZNJmc/jw6tqlLc4gkzab3btX1y5tcQaZtNnMzMDIyJltIyPddkkvYZBJm83kJMzOwtgYJN332VkHekjLcNSitBlNThpcUo88I5MktZpBJklqNYNMkrTuOgc7jN80zrZ92xi/aZzOwf7NTuM9MknSuuoc7DB12xTzJ7s/7D/0/CGmbuvOTjN5yfrf+/WMTJK0rqbvmv5WiJ02f3Ke6bv6MzvNikGW5Kwk9yd5KMmjSfYtsc6FSe5JciLJjavZVpI0XA4/v/QsNMu1r1UvZ2QngCur6lJgD7A3yVsWrfMscB3w4VewraQtbCPvpWhj7D536VlolmtfqxWDrLqON4s7mlctWudoVT0AnFzttpK2rtP3Ug49f4iivnUvxTBrt5mrZhjZcebsNCM7Rpi5qj+z0/R0jyzJ9iQPAkeBO6vqvl53sJZtJQ23jb6Xoo0xeckks++aZezcMUIYO3eM2XfN9mWgB/Q4arGqXgT2JDkP+FySi6vqkfXcNskUMAWw28lRpS1ho++laONMXjLZt+BabFWjFqvqOeBuYO9qd7TStlU1W1UTVTUxOjq62u4ltdBG30vRcOpl1OJoczZFkrOBq4Eneul8LdtKGn4bfS9Fw6mXS4s7gVuSbKcbfLdW1e1JrgWoqv1JLgDmgHOAU0luAC5abts+HIekFjp96Wn6rmkOP3+Y3efuZuaqmQ27JKXhkKrNN4hwYmKi5ubmBl2GJGmTSHKgqiaW+s6ZPSRJrWaQSZJazSCTJLWaQSZJajWDTJLUagaZ2qPTgfFx2Lat+95xPj5JBpnaotOBqSk4dAiquu9TU0MbZs4IL/XOIFM7TE/D/JmTyzI/320fMs4IL62OQaZ2OLzMJLLLtbeYM8IPL8+0+8MgUzss90SEIXxSgjPCDyfPtPvHIFM7zMzAyJmTyzIy0m0fMs4IP5w80+4fg0ztMDkJs7MwNgZJ9312tts+ZJwRfjh5pt0/BpnaY3ISnnwSTp3qvg9hiMHGP11XG8Mz7f7p6QnRkjbWRj5dVxtj5qoZpm6bOuPyomfa68MzMknaAJ5p94/PI5MkbXo+j0ySNLQMMklSqxlkkqRWM8gkSa1mkEmSWs0gkyS1mkEmSWo1g6ztfGqypC1uxSBLclaS+5M8lOTRJPuWWOfCJPckOZHkxgXtb0zyx0keb7a9fr0PYEvzqcmDLknSJrDizB5JAry2qo4n2QF8Ebi+qu5dsM53AWPANcDfVdWHm/adwM6q+lKS7wAOANdU1WMvt09n9ujR+Hg3vBYbG+tOqjtETj/LafE8dU7xI20Na5rZo7qON4s7mlctWudoVT0AnFzU/tWq+lLz+evA48AbVn8IWpJPTfZZTpJ6u0eWZHuSB4GjwJ1Vdd9qd5RkHLgMWPW2WoZPTfZZTpJ6C7KqerGq9gC7gCuSXLyanSR5HfBZ4IaqemGZdaaSzCWZO3bs2Gq637p8arLPcpK0ulGLVfUccDewt9dtmvtqnwU6VfV7L9P3bFVNVNXE6Ojoasraunxqss9yktTTqMXRJOc1n88Grgae6KXzZqDIzcDjVfVra6hTy/GpyYMuTdKA9TJq8QeAW4DtdIPv1qr61STXAlTV/iQXAHPAOcAp4DhwEfADwJ8BB5t2gF+uqjtebp+OWpQkLfRyoxZftdLGVfUw3UEai9v3L/j8DN37Z4t9EUjvpUqStDrDN7OHM11I0pay4hlZq5ye6WK++b3R6ZkuYGjvHUnSVjdcZ2TT098OsdPm57vtkqShNFxBtoVmupAkdQ1XkG2hmS4kSV3DFWRbaKYLSVLXcAXZFprpQpLUNVyjFqEbWgaXJG0Zw3VGJknacgwySVKrGWSSpFYzyCRJrWaQSZJazSCTJLWaQSZJajWDTJLUagaZJKnVDDJJUqsZZJKkVjPIJEmtZpBJklrNIJMktZpBJklqtRWDLMlZSe5P8lCSR5PsW2KdC5Pck+REkhsXfffRJEeTPLKehUuSBL2dkZ0ArqyqS4E9wN4kb1m0zrPAdcCHl9j+d4C9a6hRkqRlrRhk1XW8WdzRvGrROker6gHg5BLb/yndoJMkad31dI8syfYkDwJHgTur6r6+ViVJUo96CrKqerGq9gC7gCuSXLzehSSZSjKXZO7YsWPr3b0kaUitatRiVT0H3E0f7nlV1WxVTVTVxOjo6Hp3L0kaUr2MWhxNcl7z+WzgauCJPtclSVJPXtXDOjuBW5Jspxt8t1bV7UmuBaiq/UkuAOaAc4BTSW4ALqqqF5J8Eng7cH6SI8CHqurmPhyLJGkLWjHIquph4LIl2vcv+PwM3ftnS23/nrUUKEnSy3FmD0lSqxlkkqRWM8gkSa1mkEmSWs0gkyS1mkEmSWo1g0yS1GoGWct1DnYYv2mcbfu2MX7TOJ2DnUGXJEkbqpeZPbRJdQ52mLptivmT8wAcev4QU7dNATB5yeQgS5OkDeMZWYtN3zX9rRA7bf7kPNN3TQ+oIknaeAZZix1+/vCq2iVpGBlkLbb73N2rapekYWSQtdjMVTOM7Bg5o21kxwgzV80MqCJJ2ngGWYtNXjLJ7LtmGTt3jBDGzh1j9l2zDvSQtKWkqgZdw0tMTEzU3NzcoMuQJG0SSQ5U1cRS33lGJklqNYNMktRqBpkkqdUMMklSqxlkkqRWM8gkSa1mkEmSWs0gkyS1mkEmSWq1FYMsyVlJ7k/yUJJHk+xbYp0Lk9yT5ESSGxd9tzfJXyT5cpIPrmfxkiT18mDNE8CVVXU8yQ7gi0l+v6ruXbDOs8B1wDULN0yyHfhN4EeAI8ADST5fVY+tS/WSpC1vxTOy6jreLO5oXrVonaNV9QBwctHmVwBfrqqvVNU3gE8BP7n2siVJ6urpHlmS7UkeBI4Cd1bVfT32/wbgqQXLR5o2SZLWRU9BVlUvVtUeYBdwRZKLe+w/S3W35IrJVJK5JHPHjh3rsXtJ0la3qlGLVfUccDewt8dNjgBvXLC8C3h6mb5nq2qiqiZGR0dXU5YkaQvrZdTiaJLzms9nA1cDT/TY/wPAm5J8T5JXA+8GPv8Ka5Uk6SV6GbW4E7ilGYG4Dbi1qm5Pci1AVe1PcgEwB5wDnEpyA3BRVb2Q5P3AHwDbgY9W1aP9OBBJ0ta0YpBV1cPAZUu071/w+Rm6lw2X2v4O4I411ChJ0rKc2UOS1GoGmSSp1QwySVKrGWSSpFYzyCRJrWaQSZJazSCTJLWaQSZJajWDTJLUagaZJKnVDDJJUqsZZJKkVjPIJEmtZpBJklrNIJMktdrQBVnnYIfxm8bZtm8b4zeN0znYGXRJkqQ+6uUJ0a3ROdhh6rYp5k/OA3Do+UNM3TYFwOQlk4MsTZLUJ0N1RjZ91/S3Quy0+ZPzTN81PaCKJEn9NlRBdvj5w6tqlyS131AF2e5zd6+qXZLUfkMVZDNXzTCyY+SMtpEdI8xcNTOgiiRJ/TZUQTZ5ySSz75pl7NwxQhg7d4zZd8060EOShliqatA1vMTExETNzc0NugxJ0iaR5EBVTSz13YpnZEnOSnJ/koeSPJpk3xLrJMlvJPlykoeTXL7gu+uTPNJse8OajkSSpEV6ubR4Ariyqi4F9gB7k7xl0TrvAN7UvKaA3wZIcjHwC8AVwKXAO5O8aX1KlySphyCrruPN4o7mtfh65E8Cv9usey9wXpKdwD8E7q2q+ar6JvAnwE+tX/mSpK2up8EeSbYneRA4CtxZVfctWuUNwFMLlo80bY8Ab0vy+iQjwI8Bb1xz1ZIkNXoKsqp6sar2ALuAK5pLhgtl6c3qceC/AHcCXwAeAr651D6STCWZSzJ37NixXuuXJG1xqxp+X1XPAXcDexd9dYQzz7R2AU8329xcVZdX1duAZ4G/Wqbv2aqaqKqJ0dHR1ZQlSdrCVpw0OMkocLKqnktyNnA13bOshT4PvD/Jp4B/AjxfVV9ttv+uqjqaZDfwL4AfWmmfBw4c+FqSQ6s8lsXOB762xj7aZCsdr8c6nDzW4bRexzq23Be9zH6/E7glyXa6Z3C3VtXtSa4FqKr9wB107399GZgH3rtg+88meT1wEnhfVf3dSjusqjWfkiWZW+43B8NoKx2vxzqcPNbhtBHHumKQVdXDwGVLtO9f8LmA9y2z/Q+vpUBJkl7OUE1RJUnaeoY5yGYHXcAG20rH67EOJ491OPX9WDflXIuSJPVqmM/IJElbwFAGWZK9Sf6imcT4g4Oup1+SfDTJ0SSPDLqWfkvyxiR/nOTxZgLq6wddU7/0MlH3sGlmD/rzJLcPupZ+S/JkkoNJHkwy1I/5SHJeks8keaL5t7viz69e0X6G7dJi8zOBvwR+hO4PtR8A3lNVjw20sD5I8jbgON15LhfPtjJUmrk7d1bVl5J8B3AAuGZI/38N8NqqOp5kB/BF4PpmHtOhlOTfAxPAOVX1zkHX009JngQmqmrof0eW5Bbgz6rqI0leDYw0E2usq2E8I7sC+HJVfaWqvgF8iu6kxkOnqv6U7mwpQ6+qvlpVX2o+fx14nO58nkOnx4m6h0aSXcCPAx8ZdC1aP0nOAd4G3AxQVd/oR4jBcAbZchMYa0gkGaf728bFk1cPjR4m6h4mNwG/CJwacB0bpYA/THIgydSgi+mj7wWOAR9rLht/JMlr+7GjYQyyJScw3vAq1BdJXgd8Frihql4YdD390sNE3UMhyTuBo1V1YNC1bKC3VtXldJ/j+L7mFsEwehVwOfDbVXUZ8PdAX8YsDGOQLTuBsdqtuV/0WaBTVb836Ho2wstM1D0s3gr8RHPf6FPAlUk+PtiS+quqTk+ofhT4HN3bIcPoCHBkwdWEz9ANtnU3jEH2APCmJN/T3Fx8N91JjdVizQCIm4HHq+rXBl1PPyUZTXJe8/n0RN1PDLSoPqmqX6qqXVU1Tvff6h9V1c8MuKy+SfLaZrASzWW2H6X73MahU1XPAE8leXPTdBXQl8FZvUwa3CpV9c0k7wf+ANgOfLSqHh1wWX2R5JPA24HzkxwBPlRVNw+2qr55K/CzwMHm3hHAL1fVHYMrqW+WnKh7wDVpfXw38Lnu32W8CvhEVX1hsCX11QeATnNS8RXOnFB+3Qzd8HtJ0tYyjJcWJUlbiEEmSWo1g0yS1GoGmSSp1QwySVKrGWSSpFYzyCRJrWaQSZJa7f8D6I7gYsUuj7wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparación de los resultados predichos por el modelo con los resultados reales de la serie.\n",
    "results=model.predict(x_val)\n",
    "plt.scatter(range(len(y_val)),y_val,c='g')\n",
    "plt.scatter(range(len(results)),results,c='r')\n",
    "plt.title('validación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f0218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d7da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88482d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c8169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69768d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb054c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dc3e17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de nuevo del dataset.\n",
    "dataframe_2 = pd.read_csv('poblacion_16_65.csv', sep=\";\", usecols=[1], engine='python')\n",
    "dataframe_2 = dataframe_2.values\n",
    "values_2 = dataframe_2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4ebc1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recogida de los ultimos valores.\n",
    "values_2 = values_2[-70:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c3f84afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25008644.0</td>\n",
       "      <td>25109374.0</td>\n",
       "      <td>25202372.0</td>\n",
       "      <td>25296020.0</td>\n",
       "      <td>25387158.0</td>\n",
       "      <td>25479364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25109374.0</td>\n",
       "      <td>25202372.0</td>\n",
       "      <td>25296020.0</td>\n",
       "      <td>25387158.0</td>\n",
       "      <td>25479364.0</td>\n",
       "      <td>25571032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25202372.0</td>\n",
       "      <td>25296020.0</td>\n",
       "      <td>25387158.0</td>\n",
       "      <td>25479364.0</td>\n",
       "      <td>25571032.0</td>\n",
       "      <td>25663566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25296020.0</td>\n",
       "      <td>25387158.0</td>\n",
       "      <td>25479364.0</td>\n",
       "      <td>25571032.0</td>\n",
       "      <td>25663566.0</td>\n",
       "      <td>25797004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25387158.0</td>\n",
       "      <td>25479364.0</td>\n",
       "      <td>25571032.0</td>\n",
       "      <td>25663566.0</td>\n",
       "      <td>25797004.0</td>\n",
       "      <td>25953700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25479364.0</td>\n",
       "      <td>25571032.0</td>\n",
       "      <td>25663566.0</td>\n",
       "      <td>25797004.0</td>\n",
       "      <td>25953700.0</td>\n",
       "      <td>26102666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25571032.0</td>\n",
       "      <td>25663566.0</td>\n",
       "      <td>25797004.0</td>\n",
       "      <td>25953700.0</td>\n",
       "      <td>26102666.0</td>\n",
       "      <td>26255888.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-6)   var1(t-5)   var1(t-4)   var1(t-3)   var1(t-2)   var1(t-1)\n",
       "6   25008644.0  25109374.0  25202372.0  25296020.0  25387158.0  25479364.0\n",
       "7   25109374.0  25202372.0  25296020.0  25387158.0  25479364.0  25571032.0\n",
       "8   25202372.0  25296020.0  25387158.0  25479364.0  25571032.0  25663566.0\n",
       "9   25296020.0  25387158.0  25479364.0  25571032.0  25663566.0  25797004.0\n",
       "10  25387158.0  25479364.0  25571032.0  25663566.0  25797004.0  25953700.0\n",
       "11  25479364.0  25571032.0  25663566.0  25797004.0  25953700.0  26102666.0\n",
       "12  25571032.0  25663566.0  25797004.0  25953700.0  26102666.0  26255888.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PASOS = 6\n",
    "\n",
    "reframed_2 = series_to_supervised(values_2, PASOS, 1)\n",
    "reframed_2.drop(reframed_2.columns[[6]], axis=1, inplace=True) # Quita las columnas que queremos predecir (t).\n",
    "reframed_2.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c420af04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[30928650., 31053952., 31202808., 31256540., 31299828.,\n",
       "         31250224.]]], dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = reframed_2.values\n",
    "x_test = values[63:, :] #Coge la ultima columna que es equivalente a la ultima fila.\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3ccbcfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[30928650. 31053952. 31202808. 31256540. 31299828. 31250224.]]]\n",
      "[[[31053952. 31202808. 31256540. 31299828. 31250224. 31614934.]]]\n",
      "[[[31202808. 31256540. 31299828. 31250224. 31614934. 31699418.]]]\n",
      "[[[31256540. 31299828. 31250224. 31614934. 31699418. 31815864.]]]\n",
      "[[[31299828. 31250224. 31614934. 31699418. 31815864. 31953506.]]]\n",
      "[[[31250224. 31614934. 31699418. 31815864. 31953506. 32046520.]]]\n",
      "[[[31614934. 31699418. 31815864. 31953506. 32046520. 32179596.]]]\n",
      "[[[31699418. 31815864. 31953506. 32046520. 32179596. 32335652.]]]\n",
      "[[[31815864. 31953506. 32046520. 32179596. 32335652. 32451502.]]]\n",
      "[[[31953506. 32046520. 32179596. 32335652. 32451502. 32584542.]]]\n",
      "[[[32046520. 32179596. 32335652. 32451502. 32584542. 32715412.]]]\n",
      "[[[32179596. 32335652. 32451502. 32584542. 32715412. 32840990.]]]\n",
      "[[[32335652. 32451502. 32584542. 32715412. 32840990. 32977194.]]]\n",
      "[[[32451502. 32584542. 32715412. 32840990. 32977194. 33111020.]]]\n",
      "[[[32584542. 32715412. 32840990. 32977194. 33111020. 33241694.]]]\n",
      "[[[32715412. 32840990. 32977194. 33111020. 33241694. 33376372.]]]\n",
      "[[[32840990. 32977194. 33111020. 33241694. 33376372. 33509740.]]]\n",
      "[[[32977194. 33111020. 33241694. 33376372. 33509740. 33643820.]]]\n",
      "[[[33111020. 33241694. 33376372. 33509740. 33643820. 33779800.]]]\n",
      "[[[33241694. 33376372. 33509740. 33643820. 33779800. 33915190.]]]\n",
      "[[[33376372. 33509740. 33643820. 33779800. 33915190. 34051196.]]]\n",
      "[[[33509740. 33643820. 33779800. 33915190. 34051196. 34188136.]]]\n",
      "[[[33643820. 33779800. 33915190. 34051196. 34188136. 34325212.]]]\n",
      "[[[33779800. 33915190. 34051196. 34188136. 34325212. 34463076.]]]\n",
      "[[[33915190. 34051196. 34188136. 34325212. 34463076. 34601560.]]]\n",
      "[[[34051196. 34188136. 34325212. 34463076. 34601560. 34740412.]]]\n",
      "[[[34188136. 34325212. 34463076. 34601560. 34740412. 34879920.]]]\n",
      "[[[34325212. 34463076. 34601560. 34740412. 34879920. 35019988.]]]\n",
      "[[[34463076. 34601560. 34740412. 34879920. 35019988. 35160570.]]]\n",
      "[[[34601560. 34740412. 34879920. 35019988. 35160570. 35301770.]]]\n",
      "[[[34740412. 34879920. 35019988. 35160570. 35301770. 35443516.]]]\n",
      "[[[34879920. 35019988. 35160570. 35301770. 35443516. 35585820.]]]\n",
      "[[[35019988. 35160570. 35301770. 35443516. 35585820. 35728710.]]]\n",
      "[[[35160570. 35301770. 35443516. 35585820. 35728710. 35872172.]]]\n",
      "[[[35301770. 35443516. 35585820. 35728710. 35872172. 36016200.]]]\n",
      "[[[35443516. 35585820. 35728710. 35872172. 36016200. 36160824.]]]\n",
      "[[[35585820. 35728710. 35872172. 36016200. 36160824. 36306016.]]]\n",
      "[[[35728710. 35872172. 36016200. 36160824. 36306016. 36451790.]]]\n",
      "[[[35872172. 36016200. 36160824. 36306016. 36451790. 36598160.]]]\n",
      "[[[36016200. 36160824. 36306016. 36451790. 36598160. 36745108.]]]\n",
      "[[[36160824. 36306016. 36451790. 36598160. 36745108. 36892650.]]]\n",
      "[[[36306016. 36451790. 36598160. 36745108. 36892650. 37040780.]]]\n",
      "[[[36451790. 36598160. 36745108. 36892650. 37040780. 37189508.]]]\n",
      "[[[36598160. 36745108. 36892650. 37040780. 37189508. 37338836.]]]\n",
      "[[[36745108. 36892650. 37040780. 37189508. 37338836. 37488760.]]]\n",
      "[[[36892650. 37040780. 37189508. 37338836. 37488760. 37639290.]]]\n",
      "[[[37040780. 37189508. 37338836. 37488760. 37639290. 37790416.]]]\n",
      "[[[37189508. 37338836. 37488760. 37639290. 37790416. 37942156.]]]\n",
      "[[[37338836. 37488760. 37639290. 37790416. 37942156. 38094504.]]]\n",
      "[[[37488760. 37639290. 37790416. 37942156. 38094504. 38247464.]]]\n",
      "[[[37639290. 37790416. 37942156. 38094504. 38247464. 38401030.]]]\n",
      "[[[37790416. 37942156. 38094504. 38247464. 38401030. 38555224.]]]\n",
      "[[[37942156. 38094504. 38247464. 38401030. 38555224. 38710036.]]]\n",
      "[[[38094504. 38247464. 38401030. 38555224. 38710036. 38865464.]]]\n",
      "[[[38247464. 38401030. 38555224. 38710036. 38865464. 39021520.]]]\n",
      "[[[38401030. 38555224. 38710036. 38865464. 39021520. 39178200.]]]\n",
      "[[[38555224. 38710036. 38865464. 39021520. 39178200. 39335510.]]]\n",
      "[[[38710036. 38865464. 39021520. 39178200. 39335510. 39493452.]]]\n",
      "[[[38865464. 39021520. 39178200. 39335510. 39493452. 39652028.]]]\n",
      "[[[39021520. 39178200. 39335510. 39493452. 39652028. 39811240.]]]\n",
      "[[[39178200. 39335510. 39493452. 39652028. 39811240. 39971096.]]]\n",
      "[[[39335510. 39493452. 39652028. 39811240. 39971096. 40131588.]]]\n",
      "[[[39493452. 39652028. 39811240. 39971096. 40131588. 40292730.]]]\n",
      "[[[39652028. 39811240. 39971096. 40131588. 40292730. 40454510.]]]\n",
      "[[[39811240. 39971096. 40131588. 40292730. 40454510. 40616948.]]]\n",
      "[[[39971096. 40131588. 40292730. 40454510. 40616948. 40780036.]]]\n",
      "[[[40131588. 40292730. 40454510. 40616948. 40780036. 40943780.]]]\n",
      "[[[40292730. 40454510. 40616948. 40780036. 40943780. 41108176.]]]\n",
      "[[[40454510. 40616948. 40780036. 40943780. 41108176. 41273240.]]]\n",
      "[[[40616948. 40780036. 40943780. 41108176. 41273240. 41438960.]]]\n",
      "[[[40780036. 40943780. 41108176. 41273240. 41438960. 41605348.]]]\n",
      "[[[40943780. 41108176. 41273240. 41438960. 41605348. 41772404.]]]\n",
      "[[[41108176. 41273240. 41438960. 41605348. 41772404. 41940130.]]]\n",
      "[[[41273240. 41438960. 41605348. 41772404. 41940130. 42108530.]]]\n",
      "[[[41438960. 41605348. 41772404. 41940130. 42108530. 42277610.]]]\n",
      "[[[41605348. 41772404. 41940130. 42108530. 42277610. 42447360.]]]\n",
      "[[[41772404. 41940130. 42108530. 42277610. 42447360. 42617796.]]]\n"
     ]
    }
   ],
   "source": [
    "def agregarNuevoValor(x_test,nuevoValor):\n",
    "    for i in range(x_test.shape[2]-1):\n",
    "        x_test[0][0][i] = x_test[0][0][i+1]\n",
    "    x_test[0][0][x_test.shape[2]-1]=nuevoValor\n",
    "    return x_test\n",
    " \n",
    "results=[]\n",
    "for i in range(77):\n",
    "    parcial=model.predict(x_test)\n",
    "    results.append(parcial[0])\n",
    "    print(x_test)\n",
    "    x_test=agregarNuevoValor(x_test,parcial[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d93bb7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>31614934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>31699418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>31815864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>31953506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>32046520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>42108528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>42277608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>42447360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>42617796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>42788920.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          total\n",
       "103  31614934.0\n",
       "104  31699418.0\n",
       "105  31815864.0\n",
       "106  31953506.0\n",
       "107  32046520.0\n",
       "..          ...\n",
       "175  42108528.0\n",
       "176  42277608.0\n",
       "177  42447360.0\n",
       "178  42617796.0\n",
       "179  42788920.0\n",
       "\n",
       "[77 rows x 1 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.Index(range(103, 180, 1))\n",
    "\n",
    "\n",
    "prediccion1 = pd.DataFrame(results, index)\n",
    "prediccion1.columns = ['total']\n",
    "prediccion1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b1566461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_3 = pd.read_csv('poblacion_16_65.csv', sep=\";\", usecols=[1], engine='python')\n",
    "dataframe_3 = dataframe_3.values\n",
    "values_3 = dataframe_3.astype('float32')\n",
    "antiguo = pd.DataFrame(values_3)\n",
    "antiguo.columns = ['total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b68350a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [antiguo, prediccion1]\n",
    "\n",
    "result = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9735b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "\n",
    "result.to_csv('prueba1.csv', mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c5b04bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se representa conjuntamente los datos obtenidos tras la predicción junto con los datos reales de la serie.\n",
    "plt.plot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24cb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220d83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91bd68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
